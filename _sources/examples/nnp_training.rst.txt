.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_examples_nnp_training.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_nnp_training.py:


.. _training-example:

Train Your Own Neural Network Potential
=======================================

This example shows how to use TorchANI train your own neural network potential.


To begin with, let's first import the modules we will use:



.. code-block:: python

    import torch
    import ignite
    import torchani
    import tqdm
    import timeit
    import tensorboardX
    import os
    import sys








Now let's setup training hyperparameters. Note that here for our demo purpose
, we set both training set and validation set the ``ani_gdb_s01.h5`` in
TorchANI's repository. This allows this program to finish very quick, because
that dataset is very small. But this is wrong and should be avoided for any
serious training. These paths assumes the user run this script under the
``examples`` directory of TorchANI's repository. If you download this script,
you should manually set the path of these files in your system before this
script can run successfully.



.. code-block:: python


    # training and validation set
    try:
        path = os.path.dirname(os.path.realpath(__file__))
    except NameError:
        path = os.getcwd()
    training_path = os.path.join(path, '../dataset/ani_gdb_s01.h5')
    validation_path = os.path.join(path, '../dataset/ani_gdb_s01.h5')

    # checkpoint file to save model when validation RMSE improves
    model_checkpoint = 'model.pt'

    # max epochs to run the training
    max_epochs = 20

    # Compute training RMSE every this steps. Since the training set is usually
    # huge and the loss funcition does not directly gives us RMSE, we need to
    # check the training RMSE to see overfitting.
    training_rmse_every = 5

    # device to run the training
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # batch size
    batch_size = 1024

    # log directory for tensorboardX
    log = 'runs'








Now let's read our constants and self energies from constant files and
construct AEV computer.



.. code-block:: python

    const_file = os.path.join(path, '../torchani/resources/ani-1x_dft_x8ens/rHCNO-5.2R_16-3.5A_a4-8.params')  # noqa: E501
    sae_file = os.path.join(path, '../torchani/resources/ani-1x_dft_x8ens/sae_linfit.dat')  # noqa: E501
    consts = torchani.neurochem.Constants(const_file)
    aev_computer = torchani.AEVComputer(**consts)
    energy_shifter = torchani.neurochem.load_sae(sae_file)








Now let's define atomic neural networks. Here in this demo, we use the same
size of neural network for all atom types, but this is not necessary.



.. code-block:: python

    def atomic():
        model = torch.nn.Sequential(
            torch.nn.Linear(384, 128),
            torch.nn.CELU(0.1),
            torch.nn.Linear(128, 128),
            torch.nn.CELU(0.1),
            torch.nn.Linear(128, 64),
            torch.nn.CELU(0.1),
            torch.nn.Linear(64, 1)
        )
        return model


    nn = torchani.ANIModel([atomic() for _ in range(4)])
    print(nn)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ANIModel(
      (0): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): CELU(alpha=0.1)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): CELU(alpha=0.1)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): CELU(alpha=0.1)
        (6): Linear(in_features=64, out_features=1, bias=True)
      )
      (1): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): CELU(alpha=0.1)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): CELU(alpha=0.1)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): CELU(alpha=0.1)
        (6): Linear(in_features=64, out_features=1, bias=True)
      )
      (2): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): CELU(alpha=0.1)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): CELU(alpha=0.1)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): CELU(alpha=0.1)
        (6): Linear(in_features=64, out_features=1, bias=True)
      )
      (3): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): CELU(alpha=0.1)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): CELU(alpha=0.1)
        (4): Linear(in_features=128, out_features=64, bias=True)
        (5): CELU(alpha=0.1)
        (6): Linear(in_features=64, out_features=1, bias=True)
      )
    )


If checkpoint from previous training exists, then load it.



.. code-block:: python

    if os.path.isfile(model_checkpoint):
        nn.load_state_dict(torch.load(model_checkpoint))
    else:
        torch.save(nn.state_dict(), model_checkpoint)

    model = torch.nn.Sequential(aev_computer, nn).to(device)







Now setup tensorboardX.



.. code-block:: python

    writer = tensorboardX.SummaryWriter(log_dir=log)







Now load training and validation datasets into memory. Note that we need to
subtracting energies by the self energies of all atoms for each molecule.
This makes the range of energies in a reasonable range. The second argument
defines how to convert species as a list of string to tensor, that is, for
all supported chemical symbols, which is correspond to ``0``, which
correspond to ``1``, etc.



.. code-block:: python

    training = torchani.data.BatchedANIDataset(
        training_path, consts.species_to_tensor, batch_size, device=device,
        transform=[energy_shifter.subtract_from_dataset])

    validation = torchani.data.BatchedANIDataset(
        validation_path, consts.species_to_tensor, batch_size, device=device,
        transform=[energy_shifter.subtract_from_dataset])







When iterating the dataset, we will get pairs of input and output
``(species_coordinates, properties)``, where ``species_coordinates`` is the
input and ``properties`` is the output.

``species_coordinates`` is a list of species-coordinate pairs, with shape
``(N, Na)`` and ``(N, Na, 3)``. The reason for getting this type is, when
loading the dataset and generating minibatches, the whole dataset are
shuffled and each minibatch contains structures of molecules with a wide
range of number of atoms. Molecules of different number of atoms are batched
into single by padding. The way padding works is: adding ghost atoms, with
species 'X', and do computations as if they were normal atoms. But when
computing AEVs, atoms with species `X` would be ignored. To avoid computation
wasting on padding atoms, minibatches are further splitted into chunks. Each
chunk contains structures of molecules of similar size, which minimize the
total number of padding atoms required to add. The input list
``species_coordinates`` contains chunks of that minibatch we are getting. The
batching and chunking happens automatically, so the user does not need to
worry how to construct chunks, but the user need to compute the energies for
each chunk and concat them into single tensor.

The output, i.e. ``properties`` is a dictionary holding each property. This
allows us to extend TorchANI in the future to training forces and properties.

We have tools to deal with these data types at :attr:`torchani.ignite` that
allow us to easily combine the dataset with pytorch ignite. These tools can
be used as follows:



.. code-block:: python

    container = torchani.ignite.Container({'energies': model})
    optimizer = torch.optim.Adam(model.parameters())
    trainer = ignite.engine.create_supervised_trainer(
        container, optimizer, torchani.ignite.MSELoss('energies'))
    evaluator = ignite.engine.create_supervised_evaluator(container, metrics={
            'RMSE': torchani.ignite.RMSEMetric('energies')
        })








Now let's register some event handlers to work with tqdm to display progress:



.. code-block:: python

    @trainer.on(ignite.engine.Events.EPOCH_STARTED)
    def init_tqdm(trainer):
        trainer.state.tqdm = tqdm.tqdm(total=len(training),
                                       file=sys.stdout, desc='epoch')


    @trainer.on(ignite.engine.Events.ITERATION_COMPLETED)
    def update_tqdm(trainer):
        trainer.state.tqdm.update(1)


    @trainer.on(ignite.engine.Events.EPOCH_COMPLETED)
    def finalize_tqdm(trainer):
        trainer.state.tqdm.close()








And some event handlers to compute validation and training metrics:



.. code-block:: python

    def hartree2kcal(x):
        return 627.509 * x


    @trainer.on(ignite.engine.Events.EPOCH_STARTED)
    def validation_and_checkpoint(trainer):
        def evaluate(dataset, name):
            evaluator = ignite.engine.create_supervised_evaluator(
                container,
                metrics={
                    'RMSE': torchani.ignite.RMSEMetric('energies')
                }
            )
            evaluator.run(dataset)
            metrics = evaluator.state.metrics
            rmse = hartree2kcal(metrics['RMSE'])
            writer.add_scalar(name, rmse, trainer.state.epoch)

        # compute validation RMSE
        evaluate(validation, 'validation_rmse_vs_epoch')

        # compute training RMSE
        if trainer.state.epoch % training_rmse_every == 1:
            evaluate(training, 'training_rmse_vs_epoch')

        # checkpoint model
        torch.save(nn.state_dict(), model_checkpoint)








Also some to log elapsed time:



.. code-block:: python

    start = timeit.default_timer()


    @trainer.on(ignite.engine.Events.EPOCH_STARTED)
    def log_time(trainer):
        elapsed = round(timeit.default_timer() - start, 2)
        writer.add_scalar('time_vs_epoch', elapsed, trainer.state.epoch)








Also log the loss per iteration:



.. code-block:: python

    @trainer.on(ignite.engine.Events.ITERATION_COMPLETED)
    def log_loss(trainer):
        iteration = trainer.state.iteration
        writer.add_scalar('loss_vs_iteration', trainer.state.output, iteration)








And finally, we are ready to run:



.. code-block:: python

    trainer.run(training, max_epochs)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:03,  3.32it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:01,  4.59it/s]    epoch: 100%|##########| 11/11 [00:00<00:00,  6.26it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.25it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.37it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.02it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  5.84it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  7.86it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.38it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  5.92it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  7.99it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.51it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.37it/s]    epoch:  45%|####5     | 5/11 [00:00<00:00,  8.50it/s]    epoch:  91%|######### | 10/11 [00:00<00:00, 11.15it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 27.04it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:02,  3.46it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:01,  4.77it/s]    epoch: 100%|##########| 11/11 [00:00<00:00,  6.50it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.34it/s]    epoch:  45%|####5     | 5/11 [00:00<00:00,  8.40it/s]    epoch:  91%|######### | 10/11 [00:00<00:00, 11.08it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 26.67it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.14it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.27it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.90it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.23it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.35it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.98it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.09it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.18it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.79it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:02,  3.39it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:01,  4.67it/s]    epoch:  91%|######### | 10/11 [00:00<00:00,  6.34it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 20.01it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  5.86it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  7.94it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.46it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.42it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.63it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.34it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.47it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.67it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.36it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.54it/s]    epoch:  45%|####5     | 5/11 [00:00<00:00,  8.73it/s]    epoch:  91%|######### | 10/11 [00:00<00:00, 11.49it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 28.10it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:03,  2.81it/s]    epoch:  45%|####5     | 5/11 [00:00<00:01,  3.90it/s]    epoch:  91%|######### | 10/11 [00:00<00:00,  5.35it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 18.28it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.28it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.42it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.14it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.63it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.93it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.77it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  6.40it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.64it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 11.36it/s]
    epoch:   0%|          | 0/11 [00:00<?, ?it/s]    epoch:   9%|9         | 1/11 [00:00<00:01,  5.98it/s]    epoch:  55%|#####4    | 6/11 [00:00<00:00,  8.03it/s]    epoch: 100%|##########| 11/11 [00:00<00:00, 10.58it/s]


**Total running time of the script:** ( 0 minutes  8.700 seconds)


.. _sphx_glr_download_examples_nnp_training.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: nnp_training.py <nnp_training.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: nnp_training.ipynb <nnp_training.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_

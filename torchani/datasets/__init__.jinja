# This file has sections atomatically generated by
# tools/builtin-datasets-codegen.py, which uses the jinja template engine, *DO
# NOT MODIFY THIS FILE* unless you know what you are doing.
r"""Functions and classes for creating batched and map-like datasets.

Backends for the on-disk map-like datasets inlcude HDF5, Apache Parquet and Zarr. For a
tutorial introduction on the use of this API consult the `torchani-user-guide`.

Built-in datasets are downloaded on first instantiation. Each built-in dataset that this
module provides access to is calculated with a specific level of theory (LoT) which is
in general specified as a combination of functional/basis_set or
wavefunction_method/basis_set when appropriate.

Some of the provided built-in datasets have been published in ANI papers, and some are
external freely available datasets published elsewhere, that have been reformatted to
conform to TorchANI's API. If you use any of these datasets in your work please cite the
relevate article(s).
"""
from torchani.datasets import _utils
from torchani.datasets import filters
from torchani.datasets.anidataset import ANIDataset, concatenate
from torchani.datasets.batching import (
    BatchedDataset,
    ANIBatchedInMemoryDataset,
    ANIBatchedDataset,
    Batcher,
    create_batched_dataset,
    batch_all_in_ram,
)
from torchani.datasets.builtin import (
    _DatasetId,
    _LotId,
    # Auto-generated:
{% for ds in datasets %}
    {{ ds.name | replace("-", "_") | replace("(", "_p") | replace(")", "p_") }},
{% endfor %}
)


__all__ = [
    "BatchedDataset",
    "ANIBatchedDataset",
    "ANIBatchedInMemoryDataset",
    "ANIDataset",
    "Batcher",
    "create_batched_dataset",
    "batch_all_in_ram",
    "_utils",
    "filters",
    "concatenate",
    "_DatasetId",
    "_LotId",
    # Auto-generated:
{% for ds in datasets %}
    "{{ ds.name }}",
{% endfor %}
]


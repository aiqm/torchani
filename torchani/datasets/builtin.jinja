# This file is automatically generated by tools/builtin-datasets-codegen.py,
# which uses the jinja template engine, *DO NOT MODIFY THIS FILE* unless you
# know what you are doing.
import typing as tp
import json
from enum import Enum
from pathlib import Path

from torchani.datasets.utils import _builder
from torchani.datasets.anidataset import ANIDataset

_DATASETS_JSON_PATH = Path(__file__).parent / "builtin_datasets.json"

with open(_DATASETS_JSON_PATH, mode="rt", encoding="utf-8") as f:
    _DATASETS_SPEC = json.load(f)

# Convert csv file with format "file_name, MD5-hash" into a dictionary
_MD5S: tp.Dict[str, str] = dict()
with open(Path(__file__).resolve().parent / "md5s.csv") as f:
    lines = f.readlines()
    for line in lines[1:]:
        file_, md5 = line.split(",")
        _MD5S[file_.strip()] = md5.strip()


{% for ds in datasets %}
def {{ ds.name | replace("-", "_") | replace("(", "_p") | replace(")", "p_") }}(
    lot: str = "{{ ds.default_lot }}",
    verbose: bool = True,
    download: bool = True,
    dummy_properties: tp.Optional[tp.Dict[str, tp.Any]] = None,
    skip_check: bool = False,
) -> ANIDataset:
    lot = lot.lower()
    lots = _DATASETS_SPEC["{{ ds.name }}"]["lot"]
    if lot not in lots:
        raise ValueError(f"Wrong LoT, supported are: {set(lots) - {'default-lot'}}")

    return _builder(
        archive=lots[lot]["archive"],
        files_and_md5s={k: _MD5S[k] for k in lots[lot]["files"]},
        dummy_properties=dummy_properties,
        download=download,
        verbose=verbose,
        skip_check=skip_check,
        name="{{ ds.name }}",
        suffix=".h5"
    )


{% endfor %}
class DatasetId(Enum):
{% for ds in datasets %}
    {{ ds.name | replace("-", "_") | replace("(", "_p") | replace(")", "p_") | upper }} = "{{ ds.name }}"
{% endfor %}


class LotId(Enum):
{% for lot in lots %}
    {{ lot | replace("-", "_") | replace("(", "_p") | replace(")", "p_") | upper }} = "{{ lot }}"
{% endfor %}


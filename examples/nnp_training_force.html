

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Train Neural Network Potential To Both Energies and Forces &mdash; TorchANI 1.2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train Neural Network Potential From NeuroChem Input File" href="neurochem_trainer.html" />
    <link rel="prev" title="Train Your Own Neural Network Potential" href="nnp_training.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> TorchANI
          

          
          </a>

          
            
            
              <div class="version">
                1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips.html">Tips</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="energy_force.html">Computing Energy and Force Using Models Inside Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="ase_interface.html">Structure minimization and constant temperature MD using ASE interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using TorchScript to serialize and deploy model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vibration_analysis.html">Computing Vibrational Frequencies Using Analytical Hessian</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_from_neurochem.html">Construct Model From NeuroChem Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnp_training.html">Train Your Own Neural Network Potential</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Train Neural Network Potential To Both Energies and Forces</a></li>
<li class="toctree-l1"><a class="reference internal" href="neurochem_trainer.html">Train Neural Network Potential From NeuroChem Input File</a></li>
</ul>
<p class="caption"><span class="caption-text">TorchANI's API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">TorchANI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.models">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.data">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.utils">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.neurochem">NeuroChem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.ase">ASE Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.optim">TorchANI Optimizater</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TorchANI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Train Neural Network Potential To Both Energies and Forces</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/examples/nnp_training_force.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-examples-nnp-training-force-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="train-neural-network-potential-to-both-energies-and-forces">
<span id="force-training-example"></span><span id="sphx-glr-examples-nnp-training-force-py"></span><h1>Train Neural Network Potential To Both Energies and Forces<a class="headerlink" href="#train-neural-network-potential-to-both-energies-and-forces" title="Permalink to this headline">¶</a></h1>
<p>We have seen how to train a neural network potential by manually writing
training loop in <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>. This tutorial shows how to modify
that script to train to force.</p>
<p>Most part of the script are the same as <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>, we will omit
the comments for these parts. Please refer to <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a> for more
information</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchani</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch.utils.tensorboard</span>
<span class="kn">import</span> <span class="nn">tqdm</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <a href="https://pytorch.org/docs/master/cuda.html#torch.cuda.is_available" title="View documentation for torch.cuda.is_available"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">Rcr</span></a> <span class="o">=</span> <span class="mf">5.2000e+00</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">Rca</span></a> <span class="o">=</span> <span class="mf">3.5000e+00</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">EtaR</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">1.6000000e+01</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfR</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">9.0000000e-01</span><span class="p">,</span> <span class="mf">1.1687500e+00</span><span class="p">,</span> <span class="mf">1.4375000e+00</span><span class="p">,</span> <span class="mf">1.7062500e+00</span><span class="p">,</span> <span class="mf">1.9750000e+00</span><span class="p">,</span> <span class="mf">2.2437500e+00</span><span class="p">,</span> <span class="mf">2.5125000e+00</span><span class="p">,</span> <span class="mf">2.7812500e+00</span><span class="p">,</span> <span class="mf">3.0500000e+00</span><span class="p">,</span> <span class="mf">3.3187500e+00</span><span class="p">,</span> <span class="mf">3.5875000e+00</span><span class="p">,</span> <span class="mf">3.8562500e+00</span><span class="p">,</span> <span class="mf">4.1250000e+00</span><span class="p">,</span> <span class="mf">4.3937500e+00</span><span class="p">,</span> <span class="mf">4.6625000e+00</span><span class="p">,</span> <span class="mf">4.9312500e+00</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">Zeta</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">3.2000000e+01</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfZ</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">1.9634954e-01</span><span class="p">,</span> <span class="mf">5.8904862e-01</span><span class="p">,</span> <span class="mf">9.8174770e-01</span><span class="p">,</span> <span class="mf">1.3744468e+00</span><span class="p">,</span> <span class="mf">1.7671459e+00</span><span class="p">,</span> <span class="mf">2.1598449e+00</span><span class="p">,</span> <span class="mf">2.5525440e+00</span><span class="p">,</span> <span class="mf">2.9452431e+00</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">EtaA</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">8.0000000e+00</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfA</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.tensor" title="View documentation for torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mf">9.0000000e-01</span><span class="p">,</span> <span class="mf">1.5500000e+00</span><span class="p">,</span> <span class="mf">2.2000000e+00</span><span class="p">,</span> <span class="mf">2.8500000e+00</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">num_species</span></a> <span class="o">=</span> <span class="mi">4</span>
<span class="n">aev_computer</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">AEVComputer</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">Rcr</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">Rca</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">EtaR</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfR</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">EtaA</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">Zeta</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfA</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">ShfZ</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">num_species</span></a><span class="p">)</span>
<span class="n">energy_shifter</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">EnergyShifter</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="n">species_to_tensor</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">ChemicalSymbolsToInts</span><span class="p">(</span><span class="s1">&#39;HCNO&#39;</span><span class="p">)</span>


<span class="k">try</span><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="View documentation for os.path.dirname"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.realpath" title="View documentation for os.path.realpath"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span></a><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.html#os.getcwd" title="View documentation for os.getcwd"><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">dspath</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="View documentation for os.path.join"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">path</span></a><span class="p">,</span> <span class="s1">&#39;../dataset/ani-1x/sample.h5&#39;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">batch_size</span></a> <span class="o">=</span> <span class="mi">2560</span>
</pre></div>
</div>
<p>The code to create the dataset is a bit different: we need to manually
specify that <code class="docutils literal notranslate"><span class="pre">atomic_properties=['forces']</span></code> so that forces will be read
from hdf5 files.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">training</span><span class="p">,</span> <span class="n">validation</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="View documentation for builtins.tuple"><span class="n">data</span></a><span class="o">.</span><span class="n">load_ani_dataset</span><span class="p">(</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">dspath</span></a><span class="p">,</span> <span class="n">species_to_tensor</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">batch_size</span></a><span class="p">,</span> <span class="n">rm_outlier</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">atomic_properties</span></a><span class="o">=</span><span class="p">[</span><span class="s1">&#39;forces&#39;</span><span class="p">],</span>
    <span class="n">transform</span><span class="o">=</span><span class="p">[</span><span class="n">energy_shifter</span><span class="o">.</span><span class="n">subtract_from_dataset</span><span class="p">],</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Self atomic energies: &#39;</span><span class="p">,</span> <span class="n">energy_shifter</span><span class="o">.</span><span class="n">self_energies</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Self atomic energies:  tensor([-19.3542, -19.3542, -54.7122, -75.1628], dtype=torch.float64)
</pre></div>
</div>
<p>When iterating the dataset, we will get pairs of input and output
<code class="docutils literal notranslate"><span class="pre">(species_coordinates,</span> <span class="pre">properties)</span></code>, in this case, <code class="docutils literal notranslate"><span class="pre">properties</span></code> would
contain a key <code class="docutils literal notranslate"><span class="pre">'atomic'</span></code> where <code class="docutils literal notranslate"><span class="pre">properties['atomic']</span></code> is a list of dict
containing forces:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="View documentation for builtins.tuple"><span class="n">data</span></a> <span class="o">=</span> <span class="n">training</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">properties</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="View documentation for builtins.tuple"><span class="n">data</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">atomic_properties</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">properties</span></a><span class="p">[</span><span class="s1">&#39;atomic&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">atomic_properties</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">atomic_properties</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;list&#39;&gt;
[&#39;species&#39;, &#39;coordinates&#39;, &#39;forces&#39;]
</pre></div>
</div>
<p>Due to padding, part of the forces might be 0</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">atomic_properties</span></a><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;forces&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[     0.0083,     -0.0745,      0.0000],
        [    -0.0024,     -0.0433,      0.0000],
        [    -0.0059,      0.1177,     -0.0000],
        [     0.0000,      0.0000,      0.0000],
        [     0.0000,      0.0000,      0.0000],
        [     0.0000,      0.0000,      0.0000]])
</pre></div>
</div>
<p>The code to define networks, optimizers, are mostly the same</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">160</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">144</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">144</span><span class="p">,</span> <span class="mi">112</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">112</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">112</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.CELU" title="View documentation for torch.nn.CELU"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ANIModel</span><span class="p">([</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nn</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ANIModel(
  (0): Sequential(
    (0): Linear(in_features=384, out_features=160, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=160, out_features=128, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=128, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (1): Sequential(
    (0): Linear(in_features=384, out_features=144, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=144, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (2): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=128, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (3): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=128, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
)
</pre></div>
</div>
<p>Initialize the weights and biases.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Pytorch default initialization for the weights and biases in linear layers
is Kaiming uniform. See: <a class="reference external" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear">TORCH.NN.MODULES.LINEAR</a>
We initialize the weights similarly but from the normal distribution.
The biases were initialized to zero.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.Linear" title="View documentation for torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">):</span>
        <a href="https://pytorch.org/docs/master/nn.init.html#torch.nn.init.kaiming_normal_" title="View documentation for torch.nn.init.kaiming_normal_"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span></a><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <a href="https://pytorch.org/docs/master/nn.init.html#torch.nn.init.zeros_" title="View documentation for torch.nn.init.zeros_"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span></a><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>


<span class="n">nn</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#object" title="View documentation for builtins.object"><span class="n">init_params</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ANIModel(
  (0): Sequential(
    (0): Linear(in_features=384, out_features=160, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=160, out_features=128, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=128, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (1): Sequential(
    (0): Linear(in_features=384, out_features=144, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=144, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (2): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=128, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
  (3): Sequential(
    (0): Linear(in_features=384, out_features=128, bias=True)
    (1): CELU(alpha=0.1)
    (2): Linear(in_features=128, out_features=112, bias=True)
    (3): CELU(alpha=0.1)
    (4): Linear(in_features=112, out_features=96, bias=True)
    (5): CELU(alpha=0.1)
    (6): Linear(in_features=96, out_features=1, bias=True)
  )
)
</pre></div>
</div>
<p>Let’s now create a pipeline of AEV Computer –&gt; Neural Networks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">aev_computer</span><span class="p">,</span> <span class="n">nn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we will use Adam with weight decay for the weights and Stochastic Gradient
Descent for biases.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AdamW</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">([</span>
    <span class="c1"># H networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.000001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="c1"># C networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.000001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="c1"># N networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.000001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="c1"># O networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.000001</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">]},</span>
<span class="p">])</span>

<a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">SGD</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span></a><span class="p">([</span>
    <span class="c1"># H networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">H_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="c1"># C networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">C_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="c1"># N networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">N_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="c1"># O networks</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" title="View documentation for torch.nn.Sequential"><span class="n">O_network</span></a><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">]},</span>
<span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span></a><span class="p">(</span><span class="n">AdamW</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">SGD_scheduler</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">SGD</span></a><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>This part of the code is also the same</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">latest_checkpoint</span></a> <span class="o">=</span> <span class="s1">&#39;force-training-latest.pt&#39;</span>
</pre></div>
</div>
<p>Resume training from previously saved checkpoints:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.isfile" title="View documentation for os.path.isfile"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">latest_checkpoint</span></a><span class="p">):</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.load" title="View documentation for torch.load"><span class="n">torch</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">latest_checkpoint</span></a><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;nn&#39;</span><span class="p">])</span>
    <span class="n">AdamW</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;AdamW&#39;</span><span class="p">])</span>
    <a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">SGD</span></a><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;SGD&#39;</span><span class="p">])</span>
    <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;AdamW_scheduler&#39;</span><span class="p">])</span>
    <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">SGD_scheduler</span></a><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;SGD_scheduler&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>During training, we need to validate on validation set and if validation error
is better than the best, then save the new best model to a checkpoint</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># helper function to convert energy unit from Hartree to kcal/mol</span>
<span class="k">def</span> <span class="nf">hartree2kcal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">627.509</span> <span class="o">*</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">validate</span><span class="p">():</span>
    <span class="c1"># run validation</span>
    <span class="n">mse_sum</span> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.MSELoss" title="View documentation for torch.nn.MSELoss"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span></a><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="n">total_mse</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">batch_y</span></a> <span class="ow">in</span> <span class="n">validation</span><span class="p">:</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">true_energies</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">batch_y</span></a><span class="p">[</span><span class="s1">&#39;energies&#39;</span><span class="p">]</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_species</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_coordinates</span></a> <span class="ow">in</span> <span class="n">batch_x</span><span class="p">:</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_energies</span></a> <span class="o">=</span> <span class="n">model</span><span class="p">((</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_species</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_coordinates</span></a><span class="p">))</span><span class="o">.</span><span class="n">energies</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_energies</span></a><span class="p">)</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.cat" title="View documentation for torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="p">)</span>
        <span class="n">total_mse</span> <span class="o">+=</span> <span class="n">mse_sum</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">true_energies</span></a><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">count</span> <span class="o">+=</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <a href="https://docs.python.org/3/library/functions.html#object" title="View documentation for builtins.object"><span class="n">hartree2kcal</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/math.html#math.sqrt" title="View documentation for math.sqrt"><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span></a><span class="p">(</span><span class="n">total_mse</span> <span class="o">/</span> <span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
<p>We will also use TensorBoard to visualize our training process</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter"><span class="n">tensorboard</span></a> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter"><span class="n">tensorboard</span></a><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">()</span>
</pre></div>
</div>
<p>In the training loop, we need to compute force, and loss for forces</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.MSELoss" title="View documentation for torch.nn.MSELoss"><span class="n">mse</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.MSELoss" title="View documentation for torch.nn.MSELoss"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span></a><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;training starting from epoch&quot;</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># We only train 3 epoches here in able to generate the docs quickly.</span>
<span class="c1"># Real training should take much more than 3 epoches.</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">max_epochs</span></a> <span class="o">=</span> <span class="mi">3</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">early_stopping_learning_rate</span></a> <span class="o">=</span> <span class="mf">1.0E-5</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">force_coefficient</span></a> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># controls the importance of energy loss vs force loss</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">best_model_checkpoint</span></a> <span class="o">=</span> <span class="s1">&#39;force-training-best.pt&#39;</span>

<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">_</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">max_epochs</span></a><span class="p">):</span>
    <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/functions.html#object" title="View documentation for builtins.object"><span class="n">validate</span></a><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a><span class="p">,</span> <span class="s1">&#39;at epoch&#39;</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">learning_rate</span></a> <span class="o">=</span> <span class="n">AdamW</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>

    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">learning_rate</span></a> <span class="o">&lt;</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">early_stopping_learning_rate</span></a><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># checkpoint</span>
    <span class="k">if</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">is_better</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">best</span><span class="p">):</span>
        <a href="https://pytorch.org/docs/master/torch.html#torch.save" title="View documentation for torch.save"><span class="n">torch</span><span class="o">.</span><span class="n">save</span></a><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">best_model_checkpoint</span></a><span class="p">)</span>

    <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">step</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a><span class="p">)</span>
    <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">SGD_scheduler</span></a><span class="o">.</span><span class="n">step</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a><span class="p">)</span>

    <a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter.add_scalar"><span class="n">tensorboard</span><span class="o">.</span><span class="n">add_scalar</span></a><span class="p">(</span><span class="s1">&#39;validation_rmse&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">rmse</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span><span class="p">)</span>
    <a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter.add_scalar"><span class="n">tensorboard</span><span class="o">.</span><span class="n">add_scalar</span></a><span class="p">(</span><span class="s1">&#39;best_validation_rmse&#39;</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">best</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span><span class="p">)</span>
    <a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter.add_scalar"><span class="n">tensorboard</span><span class="o">.</span><span class="n">add_scalar</span></a><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">learning_rate</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span><span class="p">)</span>

    <span class="c1"># Besides being stored in x, species and coordinates are also stored in y.</span>
    <span class="c1"># So here, for simplicity, we just ignore the x and use y for everything.</span>
    <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">i</span></a><span class="p">,</span> <span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="View documentation for builtins.list"><span class="n">_</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">batch_y</span></a><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span>
        <span class="nb">enumerate</span><span class="p">(</span><span class="n">training</span><span class="p">),</span>
        <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">training</span><span class="p">),</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span><span class="p">)</span>
    <span class="p">):</span>

        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">true_energies</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">batch_y</span></a><span class="p">[</span><span class="s1">&#39;energies&#39;</span><span class="p">]</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a> <span class="o">=</span> <span class="p">[]</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">num_atoms</span></a> <span class="o">=</span> <span class="p">[]</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">force_loss</span></a> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">chunk</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">batch_y</span></a><span class="p">[</span><span class="s1">&#39;atomic&#39;</span><span class="p">]:</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_species</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">chunk</span></a><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_coordinates</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">chunk</span></a><span class="p">[</span><span class="s1">&#39;coordinates&#39;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_true_forces</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="View documentation for builtins.dict"><span class="n">chunk</span></a><span class="p">[</span><span class="s1">&#39;forces&#39;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_num_atoms</span></a> <span class="o">=</span> <span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_species</span></a> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">true_energies</span></a><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">num_atoms</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_num_atoms</span></a><span class="p">)</span>

            <span class="c1"># We must set `chunk_coordinates` to make it requires grad, so</span>
            <span class="c1"># that we could compute force from it</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor.requires_grad_" title="View documentation for torch.Tensor.requires_grad_"><span class="n">chunk_coordinates</span><span class="o">.</span><span class="n">requires_grad_</span></a><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_energies</span></a> <span class="o">=</span> <span class="n">model</span><span class="p">((</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_species</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_coordinates</span></a><span class="p">))</span><span class="o">.</span><span class="n">energies</span>

            <span class="c1"># We can use torch.autograd.grad to compute force. Remember to</span>
            <span class="c1"># create graph so that the loss of the force can contribute to</span>
            <span class="c1"># the gradient of parameters, and also to retain graph so that</span>
            <span class="c1"># we can backward through it a second time when computing gradient</span>
            <span class="c1"># w.r.t. parameters.</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_forces</span></a> <span class="o">=</span> <span class="o">-</span><a href="https://pytorch.org/docs/master/autograd.html#torch.autograd.grad" title="View documentation for torch.autograd.grad"><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor.sum" title="View documentation for torch.Tensor.sum"><span class="n">chunk_energies</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(),</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_coordinates</span></a><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># Now let&#39;s compute loss for force of this chunk</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_force_loss</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/nn.html#torch.nn.MSELoss" title="View documentation for torch.nn.MSELoss"><span class="n">mse</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_true_forces</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_forces</span></a><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_num_atoms</span></a>

            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_energies</span></a><span class="p">)</span>
            <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">force_loss</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">chunk_force_loss</span></a><span class="p">)</span>

        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">num_atoms</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.cat" title="View documentation for torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">num_atoms</span></a><span class="p">)</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.cat" title="View documentation for torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="p">)</span>

        <span class="c1"># Now the total loss has two parts, energy loss and force loss</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">energy_loss</span></a> <span class="o">=</span> <span class="p">(</span><a href="https://pytorch.org/docs/master/nn.html#torch.nn.MSELoss" title="View documentation for torch.nn.MSELoss"><span class="n">mse</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">predicted_energies</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">true_energies</span></a><span class="p">)</span> <span class="o">/</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor.sqrt" title="View documentation for torch.Tensor.sqrt"><span class="n">num_atoms</span><span class="o">.</span><span class="n">sqrt</span></a><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">force_loss</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/torch.html#torch.cat" title="View documentation for torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">(</span><a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">force_loss</span></a><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">loss</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">energy_loss</span></a> <span class="o">+</span> <a href="https://docs.python.org/3/library/functions.html#float" title="View documentation for builtins.float"><span class="n">force_coefficient</span></a> <span class="o">*</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">force_loss</span></a>

        <span class="n">AdamW</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">SGD</span></a><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.backward" title="View documentation for torch.Tensor.backward"><span class="n">loss</span><span class="o">.</span><span class="n">backward</span></a><span class="p">()</span>
        <span class="n">AdamW</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD.step" title="View documentation for torch.optim.SGD.step"><span class="n">SGD</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>

        <span class="c1"># write current batch loss to TensorBoard</span>
        <a href="https://pytorch.org/docs/master/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar" title="View documentation for torch.utils.tensorboard.writer.SummaryWriter.add_scalar"><span class="n">tensorboard</span><span class="o">.</span><span class="n">add_scalar</span></a><span class="p">(</span><span class="s1">&#39;batch_loss&#39;</span><span class="p">,</span> <a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="View documentation for torch.Tensor"><span class="n">loss</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">last_epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">training</span><span class="p">)</span> <span class="o">+</span> <a href="https://docs.python.org/3/library/functions.html#int" title="View documentation for builtins.int"><span class="n">i</span></a><span class="p">)</span>

    <a href="https://pytorch.org/docs/master/torch.html#torch.save" title="View documentation for torch.save"><span class="n">torch</span><span class="o">.</span><span class="n">save</span></a><span class="p">({</span>
        <span class="s1">&#39;nn&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;AdamW&#39;</span><span class="p">:</span> <span class="n">AdamW</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;SGD&#39;</span><span class="p">:</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.SGD" title="View documentation for torch.optim.SGD"><span class="n">SGD</span></a><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;AdamW_scheduler&#39;</span><span class="p">:</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">AdamW_scheduler</span></a><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;SGD_scheduler&#39;</span><span class="p">:</span> <a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="View documentation for torch.optim.lr_scheduler.ReduceLROnPlateau"><span class="n">SGD_scheduler</span></a><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="p">},</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="View documentation for builtins.str"><span class="n">latest_checkpoint</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>training starting from epoch 1
RMSE: 46.60869369722377 at epoch 1

epoch 1:   0%|          | 0/4 [00:00&lt;?, ?it/s]
epoch 1:  25%|##5       | 1/4 [00:02&lt;00:08,  2.96s/it]
epoch 1:  50%|#####     | 2/4 [00:05&lt;00:05,  2.94s/it]
epoch 1:  75%|#######5  | 3/4 [00:08&lt;00:02,  2.90s/it]
epoch 1: 100%|##########| 4/4 [00:10&lt;00:00,  2.58s/it]
epoch 1: 100%|##########| 4/4 [00:10&lt;00:00,  2.62s/it]
RMSE: 61.549629275930776 at epoch 2

epoch 2:   0%|          | 0/4 [00:00&lt;?, ?it/s]
epoch 2:  25%|##5       | 1/4 [00:02&lt;00:08,  2.85s/it]
epoch 2:  50%|#####     | 2/4 [00:05&lt;00:05,  2.87s/it]
epoch 2:  75%|#######5  | 3/4 [00:08&lt;00:02,  2.87s/it]
epoch 2: 100%|##########| 4/4 [00:10&lt;00:00,  2.55s/it]
epoch 2: 100%|##########| 4/4 [00:10&lt;00:00,  2.61s/it]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  21.895 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-nnp-training-force-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/4b6aa9678849c98dd34491f14233c2bd/nnp_training_force.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">nnp_training_force.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/d6f340cdb6315fd124adeb0070ded9d5/nnp_training_force.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">nnp_training_force.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="neurochem_trainer.html" class="btn btn-neutral float-right" title="Train Neural Network Potential From NeuroChem Input File" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="nnp_training.html" class="btn btn-neutral float-left" title="Train Your Own Neural Network Potential" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Roitberg Group

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>